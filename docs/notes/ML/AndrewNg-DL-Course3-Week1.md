# AndrewNg-DL-Course3-Week1

---

Introduction to ==ML strategy==

## 1.1 Why ML strategy



## 1.2 Orthogonalization

æ­£äº¤åŒ–

### Chain of assumptions in ML

1. Fit training set well on cost function

2. Fit dev set well on cost function

3. Fit test set well on cost function

4. Performs well in real world

## 1.3 Single number evaluation metric

### å•ä¸€æ•°å€¼è¯„ä¼°æŒ‡æ ‡

- precisionæŸ¥å‡†ç‡Pï¼ˆå›¾ç‰‡é›†ä¸­è¢«åˆ†è¾¨ä¸ºçŒ«çš„æ¦‚ç‡ï¼‰
- RecallæŸ¥å…¨ç‡Rï¼ˆå…¨æ˜¯çŒ«çš„å›¾ç‰‡é›†ä¸­åˆ†ç±»å™¨åˆ†è¾¨ä¸ºçŒ«çš„æ¦‚ç‡ï¼‰
  - æŸ¥å‡†ç‡å’ŒæŸ¥å…¨ç‡æ˜¯è¯„åˆ¤ä¸€ä¸ªåˆ†ç±»å™¨çš„é‡è¦æ ‡å‡†

> ä½†æ˜¯é€šè¿‡ä¸¤ä¸ªå‚æ•°å»åšè¯„åˆ¤æ˜¯å¾ˆéº»çƒ¦çš„ï¼Œä¸¤ä¸ªå‚æ•°åˆä¸ºä¸€ä¸ªå‚æ•°ä¼šæ›´å¥½ï¼

- F1åˆ†æ•°ï¼ˆF1 scoreï¼‰
  - ç»“åˆæŸ¥å‡†ç‡å’ŒæŸ¥å…¨ç‡çš„æ ‡å‡†æ–¹æ³•
  - æ­£å¼ï¼šæ˜¯På’ŒRçš„è°ƒå’Œå¹³å‡æ•°
  - éæ­£å¼ï¼šPå’ŒRçš„å¹³å‡æ•°

## 1.4 Satisficing and optimizing metrics

æ»¡è¶³å’Œä¼˜åŒ–æŒ‡æ ‡

å‡å¦‚æœ‰Nä¸ªmetricsï¼š

- 1ä¸ªæ˜¯optimizing ï¼›åªæœ‰ä¸€ä¸ªmetricséœ€è¦å»å°½å¯èƒ½åœ°ä¼˜åŒ–
- N-1ä¸ªæ˜¯satificingï¼› å…¶ä»–çš„metricså¿…é¡»è¦è¾¾åˆ°ä¸€å®šçš„é˜€å€¼ï¼ˆthresholdï¼‰

---

Setting up your goal

##  1.5 Train/dev/test distributions

ä¿æŒdev setsï¼ˆå¼€å‘é›†ï¼‰å’Œtest setsï¼ˆæµ‹è¯•é›†ï¼‰éƒ½æ¥è‡ªåŒä¸€åˆ†å¸ƒï¼

> ğŸ’¡Guidelineâ•
>
> Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on.

## 1.6 Size of dev and test sets

æŠŠå¤§é‡æ•°æ®åˆ†åˆ°è®­ç»ƒé›†ï¼Œç„¶åå°‘é‡æ•°æ®åˆ†åˆ°å¼€å‘é›†å’Œæµ‹è¯•é›†ã€‚

æµ‹è¯•é›†çš„æ•°é‡ï¼Œ==å¤Ÿç”¨==å°±å¥½ã€‚

## 1.7 When to change dev/test sets and metrics

åŸæ¥çš„è¯„ä¼°æŒ‡æ ‡ä¸è¶³ä»¥å»è¯„ä¼°ä¸€ä¸ªæ¨¡å‹ï¼Œå°±éœ€è¦èŠ±æ—¶é—´å®šä¹‰ä¸€ä¸ªæ–°çš„è¯„ä¼°æŒ‡æ ‡

---

==Comparing to human-level performance==

## 1.8 Why human-level performance?

Bayes optimal error è´å¶æ–¯æœ€ä¼˜é”™è¯¯ç‡

## 1.9 Avoidable bias å¯é¿å…åå·®

ä¸human-levelç›¸æ¯”ï¼Œå»å†³å®šæ¥ä¸‹æ¥è¦å…³æ³¨biasè¿˜æ˜¯varianceã€‚

åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡é‡ï¼Œå¯ä»¥ç”¨äººç±»æ°´å¹³çš„é”™è¯¯ç‡å»ä¼°è®¡æˆ–è€…ä»£æ›¿è´å¶æ–¯é”™è¯¯ç‡/è´å¶æ–¯æœ€ä¼˜é”™è¯¯ç‡ã€‚

ä¸¥æ ¼æ¥è¯´ï¼Œäººç±»æ°´å¹³çš„é”™è¯¯ç‡æ¯”è´å¶æ–¯é”™è¯¯ç‡è¦é«˜ä¸€äº›ï¼Œå› ä¸ºè´å¶æ–¯é”™è¯¯ç‡æ˜¯ç†è®ºä¸Šçš„æœ€ä¼˜é”™è¯¯ç‡ã€‚

![C1W3.1.9](pic/C1W3.1.9.png)



## 1.10 Understanding human-level performance

### Human-level error as a proxy for Bayes error

### Error analysis example

![C3W1.1.10](pic/C3W1.1.10.png)

## 1.11 Surpassing human-level performance



## 1.12 Improving your model performance

### The 2 fundamental assumptions of supervised learning

1. You can fit the training set pretty well(çœ‹æˆæ˜¯ä½ èƒ½åšåˆ°å¯é¿å…åå·®å¾ˆä½)
2. The training set performance generalizes pretty well to the dev/test set(çœ‹æˆæ–¹å·®ä¸å¤§)

### Reducing (avoidable) bias and variance

![C3W1.1.12](pic/C3W1.1.12.png)
