# 01 绪论

## 什么是机器学习

研究关于“学习算法”的一门学科。

> **深度学习**是指神经网络那一类的算法，是机器学习的子集。

- 在机器学习学习里，“模型”=“函数”=“假设”

### 假设空间和版本空间

- 一个问题可以有很多的假设空间
- “假设空间”=函数空间

| 假设空间     | 算法       | 模型<br />（通过算法可以算出一个能拟合数据的函数） |
| ------------ | ---------- | -------------------------------------------------- |
| 一元一次函数 | 线性回归   | 一个一元一次函数                                   |
| 一元二次函数 | 多项式回归 | 一个一元二次函数                                   |

- 所有能够拟合训练集的模型所构成的集合——“版本空间”

## 基本术语

- 算法
  - 从数据中学得模型的具体方法
- 模型
  - 算法的产出结果

> 严格区分算法和模型这两者的意义不大

- 样本

  - 具体的一条数据，关于一个事件或者对象的描述
  - 用（特征）向量来表示
    - 特征工程
      - 数值化，让计算机认识

- 标记🏷️

  - 也是样本的一部分
  - 一个完整的样本$(x,y)$
    - $y$是标记

- 样本空间

  - （输入空间、属性空间）表示样本的特征向量所在的空间，用花式大写的$\mathcal{X}$表示
    - 由线性代数的知识可知：==有向量便会有向量所在的空间==

- 标记空间

  - （输出空间）标记所在的空间，用花式大写的$\mathcal{Y}$表示

- 机器学习的两种任务

  - 分类和回归

    - 标记的取值类型是离散的

    - 标记的取值类型是连续的

  - 监督学习和无监督学习

    - 模型训练阶段有用到标记信息
    - 模型训练阶段没有用到标记信息

  - 数据集

    - 用集合表示
    - $x_{ij}$表示第i个样本的第j个特征

  - 模型

  - 泛化

    - **对未知事物判断**的准确与否才是衡量一个模型好坏的关键

  - 分布

    - 概率论中的概率分布
    - 假设样本空间服从一个未知“分布” $\mathcal{D}$

  - 归纳偏好

    - 不同的机器学习算法有不同的偏好

  - “奥卡姆剃刀”原则

    - 若有多个假设与观察一致，则选择最简单的那一个。
    - 但是此处简单的定义是多元的，见仁见智的，所以这个原则不常用于比较模型的优劣
      - 常用：基于模型==**在测试集上的表现**==来判别模型的优劣

  - “没有免费的午餐”定理（NFL）

    - ==众算法生而平等==

> 数据决定模型的上限，算法则是让模型无限地逼近上限