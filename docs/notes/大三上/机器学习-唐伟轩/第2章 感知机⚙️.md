# 第2章 感知机⚙️

## 2.1 感知机模型

- 二分类的线性分类模型
- ==误分类数据==驱动

### 定义

$$
f(x) = sign(w \cdot x + b)
$$

- w和b是感知机模型参数
  - w：权值（权值向量）
  - b：偏置
- 输出空间$y=\{-1,+1\}$

### 超平面的定义

$$
w \cdot x +b =0
$$



- 对应于特征空间$R^{n}$中的一个超平面$S$（用于二分类）
- w：超平面的法向量
- b：超平面的截距

> 为什么w与分解面垂直（w和$w \cdot x +b =0$这条线是垂直的）
>
> 可以算出来，证明相互垂直的点乘为0

### 目标

学习$w,b$



## 2.2 感知机的策略（损失函数）

#### 2.2.1 数据集的线性可分性

标签和预测值相乘为负值（-1），说明预测错误了。

#### 2.2.2 损失函数

- 特性

  - 函数非负
  - 没有误分类点，损失函数为0
  - 误分类点越少，误分类点离超平面越近，损失函数值就越小
  - 连续可导（所以损失函数里面没有sign()函数）

- 定义

  - $$
    L(w,b)=- \sum_{x_{i} M}y_{i}(w \cdot x_{i} +b)
    $$

## 2.3 感知机的学习算法

每次只选**一个**误分类的点

#### 2.3.1 感知机的学习算法的原始形式

损失函数的梯度
$$
公式
$$


随机选取一个误分类点对w，b进行更新("+"是因为梯度算出来时负数，减去一个负数就是“+”)
$$
w \leftarrow w+\eta y_{i}x_{i}
$$

$$
b \leftarrow b + \eta y_{i}
$$




#### 2.2.3 感知机学习算法的对偶形式

![2.1](/Users/yeezy/yeezyshappybook/docs/notes/大三上/机器学习-唐伟轩/pic/2.1.png)
